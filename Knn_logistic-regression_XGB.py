# -*- coding: utf-8 -*-
"""2nd Network Intrusion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17pYc1_Sq0ghqAAVlJ2kjJH4Of-SY8gkC
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, mean_absolute_error
from numba import jit, cuda
from timeit import default_timer as timer
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report
from shapash.explainer.smart_explainer import SmartExplainer
import shap

data = pd.read_csv("E:\python projects\leetcodepractice\IoT dataset\IoT Network Intrusion Dataset.csv")

print("original dataset shape", data.shape)
print(data.shape)
print(data.info())
print(data.head()) # showing top 5 rows of 86 columns
print(data.describe())
print(data.isna().sum().any())

plt.figure(figsize=(15,15))
corr_matrix = data.corr()
sns.heatmap(corr_matrix, annot=True)
plt.title('Correlation Matrix')
plt.show()

corr_matrix = data.corr()
plt.figure(figsize=(15,15))
plt.imshow(corr_matrix, cmap='crest', interpolation='nearest')
plt.colorbar()
plt.show()

def detection_of_zeros(data = data):
    num_zeros = {}
    for x in data:
        column = data[x]
        counts = column.value_counts()
        if 0 in counts.index:
            zeros = counts[0]
            num_zeros[x] = zeros
        else:
            zeros = 0
            num_zeros[x] = zeros
    return pd.DataFrame.from_dict(num_zeros, orient="index")

detected_zeros = detection_of_zeros(data)
plt.figure(figsize=(15,15))
sns.heatmap(detected_zeros, cmap="Blues")
plt.show()

percentage_of_zeros = detected_zeros / data.shape[0] * 100
print(f"percentage of zeros in every feature : {percentage_of_zeros}")

detecting_unnecessory_features = (percentage_of_zeros[percentage_of_zeros.values >= 80].index).tolist()
print(f"unnecessory features :{detecting_unnecessory_features}")

data.drop(columns= detecting_unnecessory_features, inplace=True)
print(f"shape of data after removing unnecessory features : {data.shape}")

detected_zeros = detection_of_zeros(data)

percentage_of_zeros = detected_zeros / data.shape[0] * 100

plt.figure(figsize=(10,10))
sns.heatmap(detected_zeros, cmap="Blues")
plt.show()

order_label = {"Anomaly":1, "Normal":0}
data['Label'] = data['Label'].map(order_label)

le = LabelEncoder()
data[['Cat']] = data[['Cat']].apply(le.fit_transform)

detecting_unnecessory_features = ['Sub_Cat','Flow_ID', 'Src_IP', 'Dst_IP', 'Timestamp', 'Init_Bwd_Win_Byts', 'Init_Fwd_Win_Byts']
data.drop(columns= detecting_unnecessory_features, axis=1, inplace=True)

# print(clean_data.info())
X = data.drop(["Cat"], axis=1)
y = data.Cat

plt.figure(figsize=(15,15))
corr_matrix = data.corr()
sns.heatmap(corr_matrix, annot=True)
plt.title('Correlation Matrix')
plt.show()

X_train, X_test, y_train, y_test = train_test_split(np.clip(X,-1, (2*32)-1), y, test_size=0.20, random_state=42)

neigh = KNeighborsClassifier()
neigh.fit(X_train, y_train)

y_pred = neigh.predict(X_test)
print ("Accuracy for Kneighbors classifier : ",accuracy_score(y_test,y_pred))
print("Report : ",classification_report(y_test, y_pred))

Cs = [0.001, 0.1, 1, 10, 100]
log_reg = LogisticRegression()
best_fit = GridSearchCV(estimator = log_reg, param_grid = dict(C=Cs) , cv = 5, scoring= 'accuracy')
best_fit.fit(X_train,y_train)
print("Best score is", best_fit.best_score_, 'for C =', float(best_fit.best_params_['C']))

log_reg = LogisticRegression(C=best_fit.best_params_['C'])
# log_reg = LogisticRegression(C=0.1)
log_reg.fit(X_train,y_train)

predicted = log_reg.predict(X_test)
accuracy = accuracy_score(y_test, predicted)
print('Accuracy score: ', accuracy)
print("Report : ",classification_report(y_test, predicted))

xgb_cl = xgb.XGBClassifier()
xgb_cl.fit(X_train, y_train)

y_pred = xgb_cl.predict(X_test)
print ("Accuracy for XG Boost : ",accuracy_score(y_test,y_pred))
print("Report : ",classification_report(y_test, y_pred))

print("shap initjs")
shap.initjs()
X_sampled = X_train.sample(100, random_state=10)
print("tree explainer")
explainer = shap.TreeExplainer(model=xgb_cl)
print("shap_values")
# shap_values = explainer.shap_values(X_test)
shap_values = explainer.shap_values(X_sampled)

shap.summary_plot(shap_values, X_sampled, plot_type="bar")

